# knowledge_harvesters.py
# çŸ¥è­˜ãƒãƒ¼ãƒ™ã‚¹ã‚¿ãƒ¼: è¤‡æ•°ã®æƒ…å ±ã‚½ãƒ¼ã‚¹ã‹ã‚‰çŸ¥è­˜ã‚’åé›†
# é’ç©ºæ–‡åº« + Wikipedia + NHK News + åè¨€ + å¤©æ°— + RSS

import time
import random
import threading
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum, auto
import urllib.request
import urllib.parse
import json
import re


class SourceType(Enum):
    """æƒ…å ±ã‚½ãƒ¼ã‚¹ã®ç¨®é¡"""
    AOZORA = auto()      # é’ç©ºæ–‡åº«ï¼ˆæ—¢å­˜ï¼‰
    WIKIPEDIA = auto()   # Wikipedia
    NHK_NEWS = auto()    # NHK ã‚„ã•ã—ã„æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹
    QUOTES = auto()      # åè¨€ãƒ»æ ¼è¨€
    WEATHER = auto()     # å¤©æ°—æƒ…å ±
    RSS = auto()         # RSSãƒ•ã‚£ãƒ¼ãƒ‰


@dataclass
class HarvestedContent:
    """åé›†ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„"""
    source: SourceType
    title: str
    content: str
    url: str = ""
    timestamp: float = field(default_factory=time.time)
    metadata: Dict = field(default_factory=dict)


class WikipediaHarvester:
    """
    Wikipedia æ—¥æœ¬èªç‰ˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ãªè¨˜äº‹ã‚’å–å¾—
    """
    
    def __init__(self):
        self.api_url = "https://ja.wikipedia.org/api/rest_v1"
        print("ğŸ“– Wikipedia Harvester Initialized.")
    
    def get_random_article(self) -> Optional[HarvestedContent]:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªè¨˜äº‹ã‚’å–å¾—"""
        try:
            # ãƒ©ãƒ³ãƒ€ãƒ ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
            random_url = "https://ja.wikipedia.org/wiki/Special:Random"
            req = urllib.request.Request(random_url, headers={'User-Agent': 'Kaname/1.0'})
            
            with urllib.request.urlopen(req, timeout=10) as response:
                final_url = response.geturl()
                title = urllib.parse.unquote(final_url.split("/wiki/")[-1])
            
            # è¨˜äº‹ã®è¦ç´„ã‚’å–å¾—
            summary_url = f"{self.api_url}/page/summary/{urllib.parse.quote(title)}"
            req = urllib.request.Request(summary_url, headers={'User-Agent': 'Kaname/1.0'})
            
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
            
            extract = data.get("extract", "")
            if not extract:
                return None
            
            return HarvestedContent(
                source=SourceType.WIKIPEDIA,
                title=data.get("title", title),
                content=extract[:500],  # æœ€å¤§500æ–‡å­—
                url=final_url,
                metadata={"type": "encyclopedia"}
            )
        except Exception as e:
            print(f"âš ï¸ Wikipedia harvest failed: {e}")
            return None


class NHKNewsHarvester:
    """
    NHK NEWS WEB EASY (ã‚„ã•ã—ã„æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹) ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
    """
    
    def __init__(self):
        self.api_url = "https://www3.nhk.or.jp/news/easy/news-list.json"
        print("ğŸ“° NHK News Harvester Initialized.")
    
    def get_random_news(self) -> Optional[HarvestedContent]:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
        try:
            req = urllib.request.Request(
                self.api_url,
                headers={'User-Agent': 'Kaname/1.0'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                raw = response.read().decode('utf-8')
                # BOMã‚’é™¤å»
                if raw.startswith('\ufeff'):
                    raw = raw[1:]
                data = json.loads(raw)
            
            # æ—¥ä»˜ã”ã¨ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã•ã‚Œã¦ã„ã‚‹
            all_news = []
            for date_key, news_list in data[0].items():
                if isinstance(news_list, list):
                    all_news.extend(news_list)
            
            if not all_news:
                return None
            
            news = random.choice(all_news)
            
            return HarvestedContent(
                source=SourceType.NHK_NEWS,
                title=news.get("title", ""),
                content=news.get("title", ""),  # æœ¬æ–‡ã¯åˆ¥é€”å–å¾—ãŒå¿…è¦
                url=f"https://www3.nhk.or.jp/news/easy/{news.get('news_id', '')}/{news.get('news_id', '')}.html",
                metadata={"date": news.get("news_prearranged_time", "")}
            )
        except Exception as e:
            print(f"âš ï¸ NHK News harvest failed: {e}")
            return None


class QuotesHarvester:
    """
    åè¨€ãƒ»æ ¼è¨€ã‚’æä¾›ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
    """
    
    def __init__(self):
        self.quotes = [
            {"text": "äººç”Ÿã¯çŸ­ã„ã€‚ã ã‹ã‚‰ã“ãã€ä»Šã‚’å¤§åˆ‡ã«ç”Ÿããªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚", "author": "ã‚»ãƒã‚«"},
            {"text": "å¤±æ•—ã¯æˆåŠŸã®ã‚‚ã¨ã€‚", "author": "æ—¥æœ¬ã®ã“ã¨ã‚ã–"},
            {"text": "çŸ¥è­˜ã¯åŠ›ãªã‚Šã€‚", "author": "ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ãƒ»ãƒ™ãƒ¼ã‚³ãƒ³"},
            {"text": "ä»Šæ—¥ã§ãã‚‹ã“ã¨ã‚’æ˜æ—¥ã«å»¶ã°ã™ãªã€‚", "author": "ãƒ™ãƒ³ã‚¸ãƒ£ãƒŸãƒ³ãƒ»ãƒ•ãƒ©ãƒ³ã‚¯ãƒªãƒ³"},
            {"text": "ç¶™ç¶šã¯åŠ›ãªã‚Šã€‚", "author": "æ—¥æœ¬ã®ã“ã¨ã‚ã–"},
            {"text": "å­¦ã³ã¦æ™‚ã«ã“ã‚Œã‚’ç¿’ã†ã€ã¾ãŸèª¬ã°ã—ã‹ã‚‰ãšã‚„ã€‚", "author": "å­”å­"},
            {"text": "å·±ã®æ¬²ã›ã–ã‚‹æ‰€ã¯äººã«æ–½ã™ã“ã¨å‹¿ã‚Œã€‚", "author": "å­”å­"},
            {"text": "äººã‚’è¦‹ã¦æ³•ã‚’èª¬ã‘ã€‚", "author": "é‡ˆè¿¦"},
            {"text": "ä¸ƒè»¢ã³å…«èµ·ãã€‚", "author": "æ—¥æœ¬ã®ã“ã¨ã‚ã–"},
            {"text": "åˆå¿ƒå¿˜ã‚‹ã¹ã‹ã‚‰ãšã€‚", "author": "ä¸–é˜¿å¼¥"},
            {"text": "ã‚ã‚Œæ€ã†ã€ã‚†ãˆã«ã‚ã‚Œã‚ã‚Šã€‚", "author": "ãƒ‡ã‚«ãƒ«ãƒˆ"},
            {"text": "äººé–“ã¯è€ƒãˆã‚‹è‘¦ã§ã‚ã‚‹ã€‚", "author": "ãƒ‘ã‚¹ã‚«ãƒ«"},
            {"text": "ä¸‡ç‰©ã¯æµè»¢ã™ã‚‹ã€‚", "author": "ãƒ˜ãƒ©ã‚¯ãƒ¬ã‚¤ãƒˆã‚¹"},
            {"text": "ç„¡çŸ¥ã®çŸ¥ã€‚", "author": "ã‚½ã‚¯ãƒ©ãƒ†ã‚¹"},
            {"text": "äººé–“ä¸‡äº‹å¡ç¿ãŒé¦¬ã€‚", "author": "ä¸­å›½ã®ã“ã¨ã‚ã–"},
            {"text": "é›¨å‚ã‚ŒçŸ³ã‚’ç©¿ã¤ã€‚", "author": "æ—¥æœ¬ã®ã“ã¨ã‚ã–"},
            {"text": "è™ç©´ã«å…¥ã‚‰ãšã‚“ã°è™å­ã‚’å¾—ãšã€‚", "author": "ä¸­å›½ã®ã“ã¨ã‚ã–"},
            {"text": "ç”Ÿãã‚‹ã¨ã¯å‘¼å¸ã™ã‚‹ã“ã¨ã§ã¯ãªã„ã€‚è¡Œå‹•ã™ã‚‹ã“ã¨ã ã€‚", "author": "ãƒ«ã‚½ãƒ¼"},
            {"text": "äººã¯åŸã€äººã¯çŸ³å£ã€äººã¯å €ã€‚", "author": "æ­¦ç”°ä¿¡ç„"},
            {"text": "æ•µã‚’çŸ¥ã‚Šå·±ã‚’çŸ¥ã‚Œã°ç™¾æˆ¦å±ã†ã‹ã‚‰ãšã€‚", "author": "å­«å­"},
        ]
        print("ğŸ’¬ Quotes Harvester Initialized.")
    
    def get_random_quote(self) -> HarvestedContent:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªåè¨€ã‚’å–å¾—"""
        quote = random.choice(self.quotes)
        return HarvestedContent(
            source=SourceType.QUOTES,
            title=quote["author"],
            content=quote["text"],
            metadata={"type": "quote"}
        )


class WeatherHarvester:
    """
    å¤©æ°—æƒ…å ±ã‚’å–å¾—ï¼ˆOpenWeatherMap ã¾ãŸã¯ wttr.inï¼‰
    """
    
    def __init__(self, city: str = "Tokyo"):
        self.city = city
        self.api_url = f"https://wttr.in/{city}?format=j1"
        print(f"ğŸŒ¤ï¸ Weather Harvester Initialized ({city}).")
    
    def get_weather(self) -> Optional[HarvestedContent]:
        """ç¾åœ¨ã®å¤©æ°—ã‚’å–å¾—"""
        try:
            req = urllib.request.Request(
                self.api_url,
                headers={'User-Agent': 'Kaname/1.0'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
            
            current = data.get("current_condition", [{}])[0]
            
            temp = current.get("temp_C", "?")
            humidity = current.get("humidity", "?")
            desc = current.get("weatherDesc", [{}])[0].get("value", "")
            
            content = f"ç¾åœ¨ã®{self.city}ã®å¤©æ°—: {desc}, æ°—æ¸©{temp}Â°C, æ¹¿åº¦{humidity}%"
            
            return HarvestedContent(
                source=SourceType.WEATHER,
                title=f"{self.city}ã®å¤©æ°—",
                content=content,
                metadata={
                    "temp": temp,
                    "humidity": humidity,
                    "desc": desc
                }
            )
        except Exception as e:
            print(f"âš ï¸ Weather harvest failed: {e}")
            return None


class RSSHarvester:
    """
    RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—
    """
    
    def __init__(self):
        self.feeds = [
            ("ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯", "https://b.hatena.ne.jp/hotentry/it.rss"),
            ("ITmedia", "https://rss.itmedia.co.jp/rss/2.0/itmedia_all.xml"),
        ]
        print("ğŸ“¡ RSS Harvester Initialized.")
    
    def get_random_article(self) -> Optional[HarvestedContent]:
        """ãƒ©ãƒ³ãƒ€ãƒ ãªRSSè¨˜äº‹ã‚’å–å¾—"""
        try:
            feed_name, feed_url = random.choice(self.feeds)
            
            req = urllib.request.Request(
                feed_url,
                headers={'User-Agent': 'Kaname/1.0'}
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                content = response.read().decode('utf-8')
            
            # ç°¡æ˜“çš„ãªXMLãƒ‘ãƒ¼ã‚¹ï¼ˆtitleã‚¿ã‚°ã‚’æŠ½å‡ºï¼‰
            titles = re.findall(r'<title>(?:<!\[CDATA\[)?(.*?)(?:\]\]>)?</title>', content)
            links = re.findall(r'<link>(.*?)</link>', content)
            
            if len(titles) < 2:
                return None
            
            # æœ€åˆã®titleã¯ãƒ•ã‚£ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
            idx = random.randint(1, min(10, len(titles) - 1))
            
            return HarvestedContent(
                source=SourceType.RSS,
                title=titles[idx] if idx < len(titles) else "",
                content=titles[idx] if idx < len(titles) else "",
                url=links[idx] if idx < len(links) else "",
                metadata={"feed": feed_name}
            )
        except Exception as e:
            print(f"âš ï¸ RSS harvest failed: {e}")
            return None


class KnowledgeHarvesterManager:
    """
    å…¨ãƒãƒ¼ãƒ™ã‚¹ã‚¿ãƒ¼ã‚’çµ±åˆç®¡ç†
    """
    
    def __init__(self):
        self.lock = threading.Lock()
        
        # å„ãƒãƒ¼ãƒ™ã‚¹ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
        self.wikipedia = WikipediaHarvester()
        self.nhk = NHKNewsHarvester()
        self.quotes = QuotesHarvester()
        self.weather = WeatherHarvester()
        self.rss = RSSHarvester()
        
        # åé›†å±¥æ­´
        self.history: List[HarvestedContent] = []
        
        print("ğŸŒ Knowledge Harvester Manager Ready.")
    
    def harvest_random(self) -> Optional[HarvestedContent]:
        """
        ãƒ©ãƒ³ãƒ€ãƒ ãªã‚½ãƒ¼ã‚¹ã‹ã‚‰çŸ¥è­˜ã‚’åé›†
        """
        sources = [
            (SourceType.WIKIPEDIA, lambda: self.wikipedia.get_random_article()),
            (SourceType.NHK_NEWS, lambda: self.nhk.get_random_news()),
            (SourceType.QUOTES, lambda: self.quotes.get_random_quote()),
            (SourceType.WEATHER, lambda: self.weather.get_weather()),
            (SourceType.RSS, lambda: self.rss.get_random_article()),
        ]
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        source_type, harvester = random.choice(sources)
        
        try:
            content = harvester()
            if content:
                with self.lock:
                    self.history.append(content)
                    # æœ€å¤§100ä»¶
                    if len(self.history) > 100:
                        self.history = self.history[-100:]
                
                print(f"ğŸ“š Harvested from {source_type.name}: {content.title[:30]}...")
            return content
        except Exception as e:
            print(f"âš ï¸ Harvest failed: {e}")
            return None
    
    def harvest_from(self, source: SourceType) -> Optional[HarvestedContent]:
        """
        æŒ‡å®šã‚½ãƒ¼ã‚¹ã‹ã‚‰çŸ¥è­˜ã‚’åé›†
        """
        harvesters = {
            SourceType.WIKIPEDIA: lambda: self.wikipedia.get_random_article(),
            SourceType.NHK_NEWS: lambda: self.nhk.get_random_news(),
            SourceType.QUOTES: lambda: self.quotes.get_random_quote(),
            SourceType.WEATHER: lambda: self.weather.get_weather(),
            SourceType.RSS: lambda: self.rss.get_random_article(),
        }
        
        if source not in harvesters:
            return None
        
        return harvesters[source]()
    
    def get_recent(self, count: int = 10) -> List[HarvestedContent]:
        """æœ€è¿‘ã®åé›†å±¥æ­´ã‚’å–å¾—"""
        with self.lock:
            return list(self.history[-count:])
    
    def get_state(self) -> Dict[str, Any]:
        """çŠ¶æ…‹ã‚’å–å¾—"""
        return {
            "history_count": len(self.history),
            "sources": [s.name for s in SourceType]
        }
