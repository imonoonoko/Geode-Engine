import time
import random
import numpy as np
import math
import threading 
import os
import json
import queue

# [Anatomical Imports]
import src.dna.config as config
from src.cortex.memory import GeologicalMemory
from src.cortex.knowledge_graph import KnowledgeGraph
from src.cortex.logic import LogicEngine
from src.cortex.knowledge_importer import KnowledgeImporter
from src.cortex.sedimentary import SedimentaryCortex
from src.body.maya_resonance import GeologicalResonance
from src.body.biorhythm import BioRhythm
from src.cortex.inference import PredictionEngine
from src.cortex.tazuna import Tazuna # Step 4: Meta-Cognition Engine
from src.body.hormones import Hormone, HormoneManager  # Phase 8: Global import for all methods

# [Extracted Cells & Bridges]
from src.cells.neuron import Neuron
from src.senses.visual_bridge import VisualMemoryBridge
from src.senses.mentor import AgniAccelerator # Phase 15.5
from src.brain_stem.motor_cortex import MotorCortex  # Phase 15.1
from src.brain_stem.sensory_cortex import SensoryCortex  # Phase 15.2
from src.brain_stem.dream_engine import DreamEngine  # Phase 15.3
from src.body.metabolism import MetabolismManager  # Phase 15.4 & 31
from src.cortex.spatial import SpatialCortex # Phase 31
from src.cortex.agni_translator import AgniTranslator  # Phase 16
from src.cortex.hdc_bridge import HDCBridge  # Phase 19

# [Body Interface]
try:
    from src.body.body_interface import BodyHAL
except ImportError:
    BodyHAL = None


# ğŸ§  BRAIN (The Core)
# ==========================================
class KanameBrain:
    def __init__(self):
        print("ğŸ§  Initializing Kaname Brain (Phase 10 Stable)...")
        self.is_alive = True
        self.time_step = 0
        
        # Thread Lock [Phase 10]
        self.lock = threading.Lock()
        
        # 1. ç”Ÿç†å±¤ (Hormones) - Phase 8: HormoneManager (The Iron Heart)
        from src.body.hormones import Hormone, HormoneManager
        self.hormones = HormoneManager()
        
        # Phase 20: éš è”½ã•ã‚ŒãŸç–²åŠ´ (Bravado System)
        # Phase 31: Managed by MetabolismManager, but Brain needs a stub for backward compat
        self.hidden_fatigue = 0.0

        # ... (lines 73-136 omitted)

        
        # 2. è¨˜æ†¶ & è¨€èª
        self.memory = GeologicalMemory(size=config.MSG_BRAIN_SIZE)
        print(self.memory.load()) 
        self.cortex = SedimentaryCortex(self.memory, max_sediments=config.SEDIMENT_MAX)
        
        # New: Tazuna Engine (Meta-Cognition)
        self.tazuna = Tazuna()
        
        # 3. æµ·é¦¬ (Deep Semantic Memory) [Phase 6]
        from src.cortex.hippocampus import Hippocampus
        self.hippocampus = Hippocampus()
        
        # Phase 6.2: Visual Bridge
        self.visual_bridge = VisualMemoryBridge(self.memory, self.cortex)
        # Inject Brain Reference for Active Inference
        self.visual_bridge._brain_ref = self 
        
        # 4. é­‚ (Resonance) [Phase 17]
        self.resonance = GeologicalResonance(self.memory, self.cortex.stomach)
        
        # Phase 30: æ„Ÿæƒ…â†’å­¦ç¿’æ¥ç¶š (Inject Brain Reference)
        self.cortex.stomach.brain_ref = self
        
        # Phase 16: Hybrid Translator (Ollama + Agni Distillation)
        # Re-enabled for high-level language generation
        self.translator = AgniTranslator(self)
        
        # Phase 19: HDCBridge (Memory Recall + G-Calculation + Prompt Injection)
        self.hdc_bridge = HDCBridge(self)
        
        # Phase 6: Feederã¯ç‹¬ç«‹ã•ã›ã‚‹ (main.pyã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã‚)
        from src.body.feeder import DataFeeder
        self.feeder = DataFeeder(food_folder="food")
        self.feeder.brain_ref = self  # Phase 30: é€€å±ˆãƒˆãƒªã‚¬ãƒ¼ç”¨
        
        # é’ç©ºæ–‡åº«ãƒãƒ¼ãƒ™ã‚¹ã‚¿ãƒ¼ï¼ˆè‡ªå‹•åé›†ï¼‰
        from src.body.aozora_harvester import AozoraHarvester
        self.aozora = AozoraHarvester(brain_ref=self)
        
        # å¤šæ§˜ãªçŸ¥è­˜åé›† (Wikipedia, News, etc.)
        from src.body.knowledge_harvesters import KnowledgeHarvesterManager
        self.knowledge_manager = KnowledgeHarvesterManager()
        
        # Phase 6: æ³¨æ„ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ (èˆˆå‘³é–¢å¿ƒãƒ™ãƒ¼ã‚¹ã®è¦–ç·š/ç§»å‹•)
        from src.brain_stem.attention_manager import AttentionManager
        self.attention = AttentionManager(self)
        
        # Phase 6: æ¦‚å¿µå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å­¦ç¿’)
        from src.cortex.concept_learner import ConceptLearner
        self.concept_learner = ConceptLearner(self, data_dir="memory")
        
        # Phase 5: Chimera Language Engine (Broca's Area)
        from src.cortex.language_center import LanguageCenter
        self.language_center = LanguageCenter(self)
        
        # Phase 6: äººæ ¼ç³» (Personality Field)
        from src.cortex.personality_field import PersonalityField
        self.personality_field = PersonalityField()
        
        # Phase 7: Minecraft Integration (Environment Body)
        # --> MOVED/DISABLED (Java Edition Used)
        # try:
        #     from src.games.minecraft.manager import MinecraftManager
        #     self.minecraft = MinecraftManager(brain=self)
        #     self.minecraft.start() # Start WebSocket Server immediately
        # except ImportError:
        #     # print("âš ï¸ Minecraft dependencies missing (websockets).")
        #     self.minecraft = None
        self.minecraft = None

        if self.minecraft:
            try:
                from src.games.minecraft.action import MinecraftActionModule
                self.minecraft_action = MinecraftActionModule(brain=self)
            except ImportError:
                 self.minecraft_action = None
        else:
             self.minecraft_action = None

        
        # 3. ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³
        self.neurons = []
        self.name_map = {}
        self._init_neurons()
        
        # çŠ¶æ…‹ãƒ•ãƒ©ã‚°
        self.is_drowsy = False
        self.is_sleeping = False
        self.inactive_counter = 0
        # Phase 31: Spatial Cortex handles Geo-Y
        # self.current_geo_y = config.BRAIN_GEO_INITIAL (Delegated to Spatial)
        
        # Throttle for Environment Resonance (Prevent Spamming)
        self._last_env_resonance_concept = None

        # Phase 23: Biorhythm Engine
        self.bio_engine = BioRhythm()
        self.prediction_engine = PredictionEngine() # Active Inference
        self.prediction_engine.brain_ref = self  # Phase 30: æ„Ÿæƒ…ãƒã‚¤ã‚¢ã‚¹äºˆæ¸¬ç”¨
        
        # Phase 2.2: Metamorphism (Inject Engine into Cortex)
        # Moved to end of __init__ to ensure spatial is ready

        # Phase 31: Moved to MetabolismManager
        # self.homeostatic_set_points = { ... }
        
        # Phase 25: Action Strategy (SSM-driven)
        self.current_action_strategy = "RESONATE"
        
        # Missing Initializations (Demon Audit Phase 21)
        self.last_thought_time = time.time()
        self.speech_queue = queue.Queue(maxsize=10)
        
        # Phase 2: Tazuna Learning Memory
        self.last_dopamine = 0.0
        self.last_tazuna_hormones = None # Snapshot for learning
        self.last_tazuna_signal = None

        # Phase 8 Step 3: Event-Driven Architecture
        from src.body.events import EventBus, Event
        self.events = EventBus()

        # Phase 7: Minecraft Integration (DISABLED - Java Edition Only)
        # Bedrock WebSocket is no longer used. Java Edition uses Mineflayer (bot.js)
        # To re-enable Bedrock: uncomment the following block
        # try:
        #     from src.games.minecraft.manager import MinecraftManager
        #     self.minecraft = MinecraftManager(brain=self)
        #     self.minecraft.start()
        # except ImportError:
        #     print("âš ï¸ Minecraft Module not found or dependencies missing.")
        #     self.minecraft = None
        self.minecraft = None  # Java Edition uses Mineflayer via mineflayer_env.py
        self._register_event_handlers()

        # Phase 9: Active Soliloquy (èƒ½å‹•çš„ã†ã‚è¨€)
        from src.cortex.soliloquy import SoliloquyManager
        self.soliloquy = SoliloquyManager(self)

        # Phase 22: Semantic Gravity Loop
        threading.Thread(target=self._gravity_loop, daemon=True).start()

        # Phase 15.5: Agni Accelerator (Background Tutor)
        self.mentor = AgniAccelerator(self)
        if config.EDUCATION_MODE:
            threading.Thread(target=self._mentor_loop, daemon=True).start()

        # Phase 6: Body HAL (Hardware Abstraction Layer)
        self.body_hal = BodyHAL() if BodyHAL else None

        # Phase 15.1: Motor Cortex (Separated Module)
        self.motor_cortex = MotorCortex(
            hormones=self.hormones,
            memory=self.memory,
            body_hal=self.body_hal,
            attention=getattr(self, 'attention', None),
            visual_bridge=self.visual_bridge
        )
        
        # Phase 15.2: Sensory Cortex (Separated Module)
        self.sensory_cortex = SensoryCortex(
            hormones=self.hormones,
            memory=self.memory,
            activate_concept_fn=self.activate_concept
        )
        
        # Phase 15.3: Dream Engine (Separated Module)
        self.dream_engine = DreamEngine(
            hormones=self.hormones,
            memory=self.memory,
            cortex=self.cortex,
            soliloquy=getattr(self, 'soliloquy', None)
        )
        
        # Phase 15.4: Metabolism Manager (Separated Module)
        # Phase 15.4 & 31: Metabolism Manager (Refactored)
        self.metabolism_manager = MetabolismManager(
            hormones=self.hormones,
            memory=self.memory,
            bio_engine=self.bio_engine
        )
        # Phase 31: Spatial Cortex
        self.spatial = SpatialCortex(self)
        
        # Phase 16: Agni Translator (å£2æ”»ç•¥)
        self.translator = AgniTranslator(
            brain=self,
            agni=self.mentor
        )

        # Phase 30: Removed (Consolidated into Phase 12 below)
        
        # Phase 3: Activity & Lesson (Full Integration)
        from src.cortex.lesson_room import LessonRoom
        self.lesson_room = LessonRoom(self)
        
        from src.brain_stem.activity_manager import ActivityManager
        self.activity_manager = ActivityManager(self)

        # Phase 2.2: Metamorphism (Inject Engine into Cortex) - Moved here
        if self.spatial:
            self.spatial.prediction_engine = self.prediction_engine

        # Phase 12: Advanced Reasoning (Common Sense)
        self.knowledge_graph = KnowledgeGraph(save_dir=self.memory.save_dir)
        self.logic_engine = LogicEngine(self)
        self.logic_engine.graph = self.knowledge_graph
        
        # Async Auto-Import
        def _auto_import():
             importer = KnowledgeImporter(self.knowledge_graph)
             importer.import_from_directory() # defaults to data/learning
        threading.Thread(target=_auto_import, daemon=True).start()
    
    @property
    def current_geo_y(self):
        return self.spatial.current_geo_y
    
    @current_geo_y.setter
    def current_geo_y(self, val):
        self.spatial.current_geo_y = val

    def _register_event_handlers(self):
        """
        ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©ã‚’ç™»éŒ²ã€‚
        å„ã‚¤ãƒ™ãƒ³ãƒˆã«å¯¾ã—ã¦ã€Œè„³ãŒã©ã†åå¿œã™ã‚‹ã‹ã€ã‚’å®šç¾©ã™ã‚‹ã€‚
        """
        from src.body.events import Event
        
        # User Interaction
        self.events.subscribe(Event.POKED, self._on_poked)
        self.events.subscribe(Event.PETTED, self._on_petted)
        
        # System
        self.events.subscribe(Event.ERROR_OCCURRED, self._on_error)
        
        print("ğŸ§  [Brain] Event handlers registered.")
    
    def _on_poked(self, **kwargs):
        """ã¤ã¤ã‹ã‚ŒãŸæ™‚ã®åå¿œ: ã‚¢ãƒ‰ãƒ¬ãƒŠãƒªãƒ³ä¸Šæ˜‡"""
        self.hormones.update(Hormone.ADRENALINE, config.DELTA_POKE)
    
    def _on_petted(self, **kwargs):
        """æ’«ã§ã‚‰ã‚ŒãŸæ™‚ã®åå¿œ: ãƒ‰ãƒ¼ãƒ‘ãƒŸãƒ³ä¸Šæ˜‡"""
        self.hormones.update(Hormone.DOPAMINE, config.DELTA_PET)
        self.is_sleeping = False  # æ’«ã§ã‚‰ã‚Œã‚‹ã¨èµ·ãã‚‹
    
    def _on_error(self, source=None, error=None, **kwargs):
        """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®åå¿œ: ã‚³ãƒ«ãƒã‚¾ãƒ¼ãƒ«ä¸Šæ˜‡ã€ã‚»ãƒ­ãƒˆãƒ‹ãƒ³ä½ä¸‹"""
        self.hormones.update(Hormone.CORTISOL, config.DELTA_PAIN_CORTISOL)
        self.hormones.update(Hormone.SEROTONIN, config.DELTA_PAIN_SEROTONIN)

        
    def _init_neurons(self):
        sensors = config.NEURON_SENSORS
        for name in sensors:
            n = Neuron(name, is_sensor=True)
            self.neurons.append(n)
            self.name_map[name] = n

    def activate_concept(self, name, boost=1.0):
        """ æ¦‚å¿µãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ï¼ˆãªã‘ã‚Œã°å³æ™‚ç”Ÿæˆï¼‰ """
        if name not in self.name_map:
            # Short-Term Memory Creation
            n = Neuron(name, is_sensor=False)
            self.neurons.append(n)
            self.name_map[name] = n
            # Trigger 'New Idea' resonance?
        
        self.name_map[name].potential += boost

    def prune_neurons(self):
        """ Apoptosis: æ­»ã‚“ã ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é™¤å» (Memory Leak Prevention) """
        # æ­»æ»…æ¡ä»¶: é›»ä½ãŒä½ãã€ã‹ã¤é•·æ™‚é–“ç™ºç«ã—ã¦ã„ãªã„ã€ã‹ã¤ã‚»ãƒ³ã‚µãƒ¼ã§ãªã„
        # ã—ãã„å€¤: Potential < 0.01 and Steps since fired > 5000 (roughly 8 min)
        with self.lock:
            alive = []
            dead_count = 0
            
            for n in self.neurons:
                if n.is_sensor:
                    alive.append(n)
                    continue
                    
                is_dead = (n.potential < 0.01) and (self.time_step - n.last_fired > 5000)
                
                if not is_dead:
                    alive.append(n)
                else:
                    dead_count += 1
                    if n.name in self.name_map:
                        del self.name_map[n.name]
            
            self.neurons = alive
            
        if dead_count > 0:
            print(f"ğŸ§¹ Pruned {dead_count} dead neurons. (Total: {len(self.neurons)})")


    def receive_sense(self, sense_data, data=None):
        """ æ„Ÿè¦šãƒ‡ãƒ¼ã‚¿ã®å—ä¿¡ (Thread Safe with Lock) """
        if not sense_data: return
        
        # Phase 7: Handle (type, data) style calls from MinecraftManager
        if isinstance(sense_data, str) and data is not None:
             sense_type = sense_data
             sense_data = data
             sense_data["type"] = sense_type
        else:
             sense_type = sense_data.get("type", "unknown")
        
        # --- Visual Memory Bridge Integration (Phase 6.2 Fix) ---
        # "sense_data" can be a dict (Atmosphere) OR a special stimulus packet (Objects)
        # We handle object processing HERE to ensure 30fps responsiveness.
        
        if "type" in sense_data and sense_data["type"] == "objects":
             tags_en = sense_data['tags']
             
             # 1. Update Memory Bridge (Sedimentation Loop)
             # Bridge handles storage. Pass snapshot for emotion tracking.
             self.visual_bridge.update(tags_en, self.hormones.as_dict())
             
             # 2. Visual Concept Activation
             with self.lock:
                 for tag in tags_en:
                     jp_tag = self.visual_bridge.translate_tag(tag)
                     self.activate_concept(jp_tag, boost=0.3)
             
             return # Object packet processed.
        
        # --- End Visual Bridge Integration ---

        with self.lock:
            # è¦–è¦šåˆºæ¿€ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¸å…¥åŠ›
            for name, val in sense_data.items():
                if name in self.name_map:
                    self.name_map[name].potential += val * 0.2
            
            # Phase 20: å…‰åˆæˆ (Photosynthesis)
            if 'photosynthesis_rate' in sense_data:
                gain = sense_data['photosynthesis_rate']
                if gain > 0:
                    self.hormones.update(Hormone.GLUCOSE, gain)
                    # å…‰ã‚’æµ´ã³ã‚‹ã¨å°‘ã—å¹¸ã› (Dopamine)
                    if random.random() < 0.1:
                        self.hormones.update(Hormone.DOPAMINE, 5.0)

            # Phase 7: Minecraft Integration (Refactored to SpatialCortex)
            if sense_type == "MC_TRAVEL":
                self.spatial.process_sense(sense_data)

        # Phase 7: Minecraft keeps the brain awake
        if "MC_" in str(sense_data): # Check if it's a Minecraft event
            self.last_thought_time = time.time()
            self.is_sleeping = False
            self.is_drowsy = False







    def think(self):
        """ æ€è€ƒã‚µã‚¤ã‚¯ãƒ« (Thread Safe with Lock) """
        self.time_step += 1
        
        with self.lock:
            # Phase 20: é£¢é¤“ãƒ¢ãƒ¼ãƒ‰ (Starvation / Coma)
            glucose = self.hormones.get(Hormone.GLUCOSE)
            
            if glucose < 5.0 or self.hidden_fatigue > 50.0:
                if self.time_step % 10 == 0:
                    print(f"ğŸ’€ æ˜ç¡çŠ¶æ…‹ (Coma). è¡€ç³–å€¤: {glucose:.1f}, ç–²åŠ´åº¦: {self.hidden_fatigue:.1f}")
                return None # æ€è€ƒåœæ­¢

            # Phase 6: Scale Adjusted
            serotonin = self.hormones.get(Hormone.SEROTONIN)
            h_bias = 1.0 + ((serotonin - 50.0) / 100.0)
            
            # Phase 20: æ€è€ƒã‚³ã‚¹ãƒˆ (Thinking Cost)
            # è€ƒãˆã‚‹ã ã‘ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä½¿ã†
            self.hormones.update(Hormone.GLUCOSE, -0.01)

            # Phase 20: èªçŸ¥ãƒã‚¤ã‚º (Cognitive Noise)
            # ä½è¡€ç³–æ™‚ã¯ã€Œã¼ãƒ¼ã£ã¨ã™ã‚‹ã€ (ç¢ºç‡çš„ã«ã‚¹ã‚­ãƒƒãƒ—)
            if glucose < config.THRESHOLD_LOW and random.random() < 0.3:
                return None 
            
            active_thoughts = []
            for n in self.neurons:
                n.decay(h_bias)
                if n.potential >= 1.0:
                    n.fire(self.time_step)
                    if not n.is_sensor: 
                        active_thoughts.append(n.name)
            
            # User Tuning: Remember = Eat
            # è¨˜æ†¶ã‚’æ€ã„å‡ºã™ã“ã¨ã§ã‚¨ãƒãƒ«ã‚®ãƒ¼ãŒå›å¾©ã™ã‚‹ï¼ˆç²¾ç¥çš„æº€è¶³æ„Ÿï¼‰
            if active_thoughts:
                # 1ã¤æ€ã„å‡ºã™ãŸã³ã« 0.5 å›å¾© (æœ€å¤§ 2.0/tick)
                recovery = min(2.0, len(active_thoughts) * 0.5)
                self.hormones.update(Hormone.GLUCOSE, recovery)
                        
                        # Resonance REMOVED: Was causing excessive sound frequency.
                        # Autonomous loop handles ambient sounds now.

            # Phase 22: Impulsive Action (Boredom -> Hallucination)
            # é€€å±ˆãŒé™ç•Œã‚’è¶…ãˆã‚‹ã¨ã€ãƒ©ãƒ³ãƒ€ãƒ ãªè¨˜æ†¶ãŒç™ºç«ã™ã‚‹ (Internal Stimulation)
            boredom = self.hormones.get(Hormone.BOREDOM)
            if boredom > 80.0 and random.random() < 0.05:
                impulse_word = self.memory.get_random_concept(refresh=True)
                if impulse_word:
                    active_thoughts.append(impulse_word)
                    print(f"âš¡ è¡å‹•çš„æƒ³èµ· (Impulse): {impulse_word} (é€€å±ˆåº¦: {boredom:.2f})")
                    # è¡å‹•ã«ã‚ˆã‚Šå°‘ã—ã‚¹ãƒƒã‚­ãƒªã™ã‚‹
                    self.hormones.update(Hormone.BOREDOM, -0.2)
                    self.hormones.update(Hormone.STIMULATION, 0.2)




            

            # çœ ã‚Šåˆ¤å®š
            if active_thoughts:
                self.last_thought_time = time.time()
                self.is_sleeping = False
                self.is_drowsy = False
            else:
                # Minecraftæ¥ç¶šä¸­ã¯çœ ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼ˆèº«ä½“æ´»å‹•ã‚’å„ªå…ˆï¼‰
                mc_active = hasattr(self, 'minecraft') and self.minecraft and self.minecraft.current_state.get("connected")
                
                if not mc_active:
                    if time.time() - self.last_thought_time > 20: # 20ç§’æ²ˆé»™ã§ã†ã¨ã†ã¨
                        self.is_drowsy = True
                    if time.time() - self.last_thought_time > 60: # 60ç§’æ²ˆé»™ã§ç¡çœ 
                        self.is_sleeping = True
                else:
                    # Minecraftä¸­ã€‚ã‚‚ã—å¯ã¦ã—ã¾ã£ã¦ã„ãŸã‚‰å¼·åˆ¶è¦šé†’
                    self.is_sleeping = False
                    self.is_drowsy = False

            # --- Auto-Save (Periodic) ---
            if self.time_step % 300 == 0:
                # Run save in background thread to avoid blocking thought?
                # For now, do it inline, optimization later if needed.
                self.save_memory()
                # print("ğŸ’¾ Memory/Cortex Auto-Saved.")

            # Phase 6 & 13: Digestion Cycle (While Sleeping)
            if self.is_sleeping and self.time_step % 100 == 0:
                self._dream_process()

            # (Duplicate removed - Demon Audit Phase 21)

            # ç™ºè©±äºˆç´„ (Pre-calculation inside lock)
            impulse_ir = None
            impulse_word = None
            
            if active_thoughts and self.time_step % 15 == 0 and not self.is_sleeping:
                word = random.choice(active_thoughts)
                
                # === Phase 28: Brain Wiring (Active Inference) ===
                # 1. Current Strategy (from Input/Surprise)
                strategy = self.current_action_strategy
                
                # 2. Homeostatic Overrides (Deficits drive Strategy)
                glucose = self.hormones.get(Hormone.GLUCOSE)
                dopamine = self.hormones.get(Hormone.DOPAMINE)
                
                if glucose < config.THRESHOLD_LOW:
                    pass # Hungry logic future expansion
                elif dopamine < config.THRESHOLD_LOW and strategy != "PROBE":
                    # Depressed -> Seek Joy (Memory Pivot)
                    strategy = "JOY_SEEKING"
                    
                # 3. Epistemic Visual Control
                if strategy == "PROBE":
                    # If we are curious, Look for what we are thinking about
                    self.visual_bridge.set_expectation(word)
                
                # 4. Execute Cortex Retrieval
                
                # Phase 2: Tazuna Learning Step `(Reward Calculation)`
                current_dopamine = self.hormones.get(Hormone.DOPAMINE)
                delta_dopamine = current_dopamine - self.last_dopamine
                
                if self.last_tazuna_hormones and self.last_tazuna_signal:
                    # Previous Action Resulted in this Delta?
                    # We learn if the delta is significant
                    self.tazuna.learn(self.last_tazuna_hormones, self.last_tazuna_signal.mode, delta_dopamine)

                # Execute Modulation
                tazuna_signal = self.tazuna.modulate(self.hormones)
                
                # Store State for Next Learning Step
                self.last_dopamine = current_dopamine
                self.last_tazuna_hormones = self.hormones.as_dict() # Snapshot
                self.last_tazuna_signal = tazuna_signal
                
                # Log Tazuna State
                if tazuna_signal.mode != "NORMAL":
                     icon = "ğŸ²" if tazuna_signal.mode == "DIVERGE" else "ğŸ¯"
                     if tazuna_signal.mode == "PANIC": icon = "ğŸ›¡ï¸"
                     
                     # Determine trigger for log
                     trigger = "SEROTONIN"
                     val = self.hormones.get(Hormone.SEROTONIN)
                     if tazuna_signal.mode == "DIVERGE":
                         trigger = "BOREDOM"
                         val = self.hormones.get(Hormone.BOREDOM)
                     elif tazuna_signal.mode == "PANIC":
                         trigger = "SURPRISE"
                         val = self.hormones.get(Hormone.SURPRISE)
                         
                     print(f"ğŸ [Tazuna] {icon} {tazuna_signal.mode} (Temp: {tazuna_signal.temperature:.1f}) | {trigger}: {val:.1f}%")
                     print(f"   â””â”€ Why: \"{tazuna_signal.reason}\"")
                
                ir_data = self.cortex.speak(word, strategy=strategy, tazuna_signal=tazuna_signal)
                
                if ir_data: 
                    # Inject Strategy into Packet for Translator
                    ir_data["strategy"] = strategy
                    
                    if word in self.memory.concepts: 
                        coords = self.memory.get_coords(word)
                        if len(coords) >= 2:
                            self.current_geo_y = coords[1]
                    
                    # çŠ¶æ…‹ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ (Lockä¸­ã«å–å¾—)
                    ir_data["emotions"] = self.hormones.as_dict()
                    impulse_ir = ir_data
                    impulse_word = word
                    
                    # Resonance for Speech (Loud)
                    self.resonance.impact(word, force=0.8)
                else:
                    self.resonance.impact(word, force=0.5)

        # === OUTSIDE LOCK (Safe for Network I/O) ===
        speech_payload = None
        
        # Phase 9: Active Soliloquy (èƒ½å‹•çš„ã†ã‚è¨€)
        # think_aloud() ã¯ lock ã®å¤–ã§å‘¼ã¶ï¼ˆç™ºè©±ãŒãƒ–ãƒ­ãƒƒã‚¯ã™ã‚‹ã¨å±é™ºï¼‰
        if self.soliloquy and not self.is_sleeping:
            soliloquy_speech = self.soliloquy.think_aloud()
            if soliloquy_speech and not impulse_ir:
                # impulse_ir ãŒã‚ã‚‹å ´åˆã¯é€šå¸¸ç™ºè©±ã‚’å„ªå…ˆ
                # soliloquy ã¯æ²ˆé»™æ™‚ã®ã¿å–‹ã‚‹
                impulse_ir = {"text": soliloquy_speech, "strategy": "SOLILOQUY"}
                impulse_word = "soliloquy"
        
        # Check Async Speech Queue
        try:
            if not self.speech_queue.empty():
                speech_payload = self.speech_queue.get_nowait()
        except Exception as e:
            # DEF-07 ä¿®æ­£: å…·ä½“çš„ãªä¾‹å¤–ã‚¿ã‚¤ãƒ—ã‚’ã‚­ãƒ£ãƒƒãƒ
            if "Empty" not in str(type(e).__name__):
                print(f"âš ï¸ Speech Queue Error: {e}")

        if impulse_ir:
             # æ€è€ƒã‚’è¨€èªåŒ– (Async to prevent death)
             # Fire and forget thread
             threading.Thread(target=self._async_speak_task, args=(impulse_ir, impulse_word), daemon=True).start()

        # === Phase 8: Minecraft Autonomous Action (AWAKE STATE) ===
        # èµ·ãã¦ã„ã‚‹æ™‚ã«Minecraftæ¥ç¶šä¸­ãªã‚‰è‡ªå¾‹çš„ã«å‹•ã
        if hasattr(self, 'minecraft') and self.minecraft:
            state = self.minecraft.current_state
            if state and state.get("connected"):
                if self.time_step % 5 == 0:  # 5ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è‡ªç™ºè¡Œå‹•
                    pos = state.get("position") or {}
                    mx, mz = pos.get("x", 0), pos.get("z", 0)
                    self._decide_minecraft_action(mx, mz)

        return speech_payload

    
    def _dream_process(self):
        """
        Phase 6: Sleep & Consolidation Logic (Demons of Dream)
        ç¡çœ ä¸­ã«è¨˜æ†¶ã‚’æ•´ç†ã—ã€åœ°è³ªå­¦çš„è¨˜æ†¶åœ°å›³ã‚’æ›¸ãæ›ãˆã‚‹ã€‚
        """
        print("ğŸ’¤ Demons of Dream: Organizing chaos into order...")
        
        # 1. è¨˜æ†¶ã®æ¶ˆåŒ–ãƒ»å‰ªå®š (Stomach & Cortex)
        self.cortex.digest_memories()
        
        # Phase 7: Minecraft Fallback (æ™‚ã€…è‡ªç™ºçš„ã«å‹•ã)
        if hasattr(self, 'minecraft') and self.minecraft and self.minecraft.current_state.get("connected"):
            if self.time_step % 10 == 0:  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«è‡ªç™ºè¡Œå‹•ï¼ˆ10å€é »åº¦UPï¼‰
                pos = self.minecraft.current_state.get("position", {})
                mx, mz = pos.get("x", 0), pos.get("z", 0)
                if self.time_step % 50 == 0:
                    print(f"ğŸ¤– [AUTO] Autonomous MC action: ({mx:.1f}, {mz:.1f})")
                self._decide_minecraft_action(mx, mz)
        
        # [Phase 17] Tiered Memory Pruning
        # çœ ã£ã¦ã„ã‚‹é–“ã«çŸ­æœŸè¨˜æ†¶(RAM)ã‚’æ•´ç†ã—ã€é•·æœŸè¨˜æ†¶(SQLite)ã¸æº¢ã‚ŒãŸåˆ†ã‚’æˆ»ã™
        if self.time_step % 200 == 0:
             if hasattr(self, 'knowledge_graph'):
                 # Keep 500k active concepts (~1GB RAM). The rest reside in SQLite.
                 self.knowledge_graph.prune(limit=500000)

        # 1. å‹¾é…é™ä¸‹æ³• (Gradient Following)
        result = self.memory.forget_forgotten_concepts()
        forgotten, composted_valence = result if isinstance(result, tuple) else (result, 0.0)
        
        if forgotten:
            self.cortex.stomach.forget_concepts(forgotten)
            # æ€§æ ¼ã¸ã®è»¢åŒ–
            if abs(composted_valence) > 0.1:
                mood_shift = -composted_valence * 0.05
                self.hormones.update(Hormone.SEROTONIN, mood_shift)
        
        # 3. Synaptic-Geological Bridge (The Core Feature)
        # å¼·ã„ã‚·ãƒŠãƒ—ã‚¹çµåˆï¼ˆå…±èµ·ï¼‰ã‚’æŒã¤æ¦‚å¿µåŒå£«ã‚’ç‰©ç†çš„ã«å¼•ãå¯„ã›ã‚‹
        if self.cortex.stomach:
            strong_links = self.cortex.stomach.get_strong_links(limit=10, threshold=1.5)
            if strong_links:
                print(f"ğŸ›Œ Semantic Gravity: Pulling {len(strong_links)} pairs together based on episodes...")
                for u, v, weight in strong_links:
                    # çµåˆå¼·åº¦ã«å¿œã˜ã¦å¼•åŠ›ã‚’ã‹ã‘ã‚‹ (æœ€å¤§ 0.8)
                    attraction = min(0.8, weight * 0.1)
                    
                    # Mutual Attraction (åŒæ–¹å‘å¼•åŠ›)
                    # ãŠäº’ã„ã«å¼•ãå¯„ã›åˆã†ã“ã¨ã§ã€ä¸­é–“ã«æ–°ã—ã„æ„å‘³ã®è°·ã‚’ä½œã‚‹
                    self.memory.apply_gravity(u, v, attraction)
                    self.memory.apply_gravity(v, u, attraction)
                    
                    # if res: print(f"  - {res}")
        
    def _async_speak_task(self, impulse_ir, impulse_word):
        """ Background Translation Task with Verbal Reasoning (CoT) """
        try:
            # === Phase 6: No-LLM Speech (Fragment Concatenation) ===
            # è¨˜æ†¶æ–­ç‰‡ã‚’ç›´æ¥çµåˆã—ã¦ã†ã‚è¨€ã‚’ç”Ÿæˆ
            fragments = impulse_ir.get("fragments", [])
            concept = impulse_ir.get("concept", "")
            valence = impulse_ir.get("valence", 0.0)
            
            # 1. æ–­ç‰‡ã‚’çµåˆ (ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦è‡ªç„¶ã•ã‚’æ¼”å‡º)
            if "text" in impulse_ir and impulse_ir["text"]:
                draft_text = impulse_ir["text"]  # Use pre-generated text (Chimera/Soliloquy)
            elif fragments:
                random.shuffle(fragments)
                draft_text = "".join(fragments[:3])  # æœ€å¤§3æ–­ç‰‡
            else:
                draft_text = concept  # æ–­ç‰‡ãŒãªã‘ã‚Œã°æ¦‚å¿µåã ã‘
            
            # 2. æ„Ÿæƒ…ã«å¿œã˜ãŸä¿®é£¾ (Instinctive Decoration)
            if valence > 0.5:
                draft_text = f"â€¦{draft_text}â€¦ã™ãâ€¦"
            elif valence < -0.3:
                draft_text = f"â€¦{draft_text}â€¦æ€–ã„â€¦"
            else:
                draft_text = f"â€¦{draft_text}â€¦"
            
            # 3. Ponder (Simulate) - ç¶­æŒ
            current_hour = time.localtime().tm_hour
            instability = self.prediction_engine.simulate(draft_text, current_hour)
            final_text = draft_text
            
            # 4. Hesitation (if unstable)
            if instability > 0.4:
                hesitations = ["ã‚ã®â€¦", "ãˆã£ã¨â€¦", "ã‚“ãƒ¼â€¦", "â€¦"]
                final_text = random.choice(hesitations) + draft_text
            
            payload = {
                 "text": final_text,
                 "focus": impulse_word,
                 "context": self.memory.get_context(impulse_word),
                 "instability": instability # For UI debug
            }
            self.speech_queue.put(payload)
            
        except Exception as e:
            print(f"âš ï¸ Async Speech Failed: {e}")

    def _gravity_loop(self):
        """ Phase 22: Semantic Gravity Background Process """
        print("ğŸŒŒ Gravity Engine Started.")
        while self.is_alive:
            try:
                # Sleep interval (Slow Plate Tectonics)
                sleep_time = 5.0
                # Faster during sleep (Dream Migration)
                if self.is_sleeping: sleep_time = 1.0
                
                time.sleep(sleep_time)
                
                # Pick Random Pair
                subject = self.memory.get_random_concept()
                attractor = self.memory.get_random_concept()
                
                if not subject or not attractor or subject == attractor:
                    continue
                
                # Calculate Similarity (Hippocampus)
                # This might be slow (model run), so do it outside locks.
                sim = self.hippocampus.get_similarity(subject, attractor)
                
                # Apply Gravity (Memory)
                # Threshold: Only move if similarity > 0.5
                if sim > 0.5:
                    res = self.memory.apply_gravity(subject, attractor, sim)
                    # if res: print(res)  # Too verbose?
                    
                # === Phase 29: Motor Cortex (Embodied Gradient) ===
                if self.visual_bridge.senses and self.time_step % 5 == 0:
                     self.motor_cortex.update()  # Phase 15.1: Delegated to MotorCortex
                    
            except Exception as e:
                print(f"âš ï¸ Gravity Error: {e}")
                time.sleep(5.0)

    def _mentor_loop(self):
        """ Phase 15.5: Agni Accelerator Background Loop """
        print("ğŸ”¥ Agni Accelerator: Background Tutor Started.")
        while self.is_alive:
            try:
                # Wait for interval
                time.sleep(config.MENTOR_AUTO_LOOP_INTERVAL)
                
                # Check conditions
                # Phase 32: Hypnopedia (Sleep Learning)
                # If Hypnopedia is ON, we learn even while sleeping.
                should_learn = config.EDUCATION_MODE and (config.AGNI_HYPNOPEDIA or (not self.is_sleeping and not self.is_drowsy))

                if should_learn:
                    # Pick a seed topic from existing memory to expand upon
                    seed = self.memory.get_random_concept() 
                    
                    # [Diversity Fix]: Randomly rotate Agni's persona
                    if hasattr(self.mentor, 'set_persona'):
                         new_persona = random.choice(config.AGNI_PERSONA_ROTATION)
                         self.mentor.set_persona(new_persona)

                    # [Diversity Fix]: If memory is empty or stuck on "Kaname", inject fresh concepts
                    if not seed or seed == "Kaname" or seed == "ã‚«ãƒŠãƒ¡" or seed == "User" or seed == "AI" or len(seed) < 2:
                         fallback_seeds = ["ä¸–ç•Œ", "æ™‚é–“", "å‘½", "å¿ƒ", "å¤¢", "æ˜Ÿ", "æµ·", "äººé–“", "è¨˜æ†¶", "è¨€è‘‰"]
                         seed = random.choice(fallback_seeds)

                    if seed:
                        # Inject knowledge (Matrix Mode)
                        # Agni autonomously teaches about the seed
                        if self.mentor.inject_knowledge(seed):
                            self.hormones.update(Hormone.DOPAMINE, 2.0)
                            # Checking Graduation
                            if random.random() < 0.05: # Occasional check
                                if self.mentor.check_graduation():
                                    print("ğŸ“ Kaname is ready to graduate!")
                                    # config.EDUCATION_MODE = False (Automatic OFF?)
                
            except Exception as e:
                print(f"ğŸ”¥ Mentor Loop Error: {e}")
                time.sleep(60) # Backoff

    # Phase 15.1: _update_motor_cortex moved to motor_cortex.py

    def input_stimulus(self, text):
        """ å¤–éƒ¨ã‹ã‚‰ã®è¨€èªå…¥åŠ› """
        # ã“ã“ã‚‚ãƒ­ãƒƒã‚¯ã™ã¹ãã ãŒã€input_stimulus ã¯ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã®UIã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ã€
        # Lockã‚’å–å¾—ã—ã¦å®‰å…¨ã«æ›´æ–°ã™ã‚‹
        with self.lock:
             # === Phase 6: æ¦‚å¿µæ•™ç¤ºã®æ¤œå‡º ===
             # ãƒ‘ã‚¿ãƒ¼ãƒ³: ã€Œã“ã‚Œã¯ã€‡ã€‡ã ã‚ˆã€ã€Œã“ã‚Œã¯ã€‡ã€‡ã§ã™ã€
             import re
             teach_pattern = r'ã“ã‚Œã¯(.+?)(ã ã‚ˆ|ã§ã™|ã ã­|ã­)$'
             match = re.search(teach_pattern, text.strip())
             if match and hasattr(self, 'concept_learner'):
                 concept_name = match.group(1).strip()
                 if concept_name:
                     if self.concept_learner.teach(concept_name):
                         # æ•™ç¤ºæˆåŠŸ â†’ ãƒ›ãƒ«ãƒ¢ãƒ³å¤‰åŒ–ã®ã¿ (ã‚µã‚¤ãƒ¬ãƒ³ãƒˆå­¦ç¿’)
                         self.hormones.update(Hormone.OXYTOCIN, 15.0)  # ä¿¡é ¼æ„Ÿ
                         self.hormones.update(Hormone.DOPAMINE, 10.0)  # å–œã³
                         # ç™ºè©±ã¯ã—ãªã„ã€‚æ–­ç‰‡ãŒè¨˜æ†¶ã«å…¥ã‚Šã€è‡ªç„¶ã¨ã†ã‚è¨€ã«å‡ºã¦ãã‚‹
                         # return ã—ãªã„ â†’ é€šå¸¸ã®å…¥åŠ›å‡¦ç†ã‚‚è¡Œã†
             
             # === ACTIVE INFERENCE CYCLE (Perception Learning) ===
             # 1. Predict & Observe BEFORE Learning
             current_hour = time.localtime().tm_hour
             surprise, obs_mood = self.prediction_engine.observe(text, current_hour)
             self.hormones.set(Hormone.SURPRISE, surprise)
             
             # 2. PANIC CHECK (Circuit Breaker)
             # If surprise is too high (Cognitive Overload), reject input to minimize free energy.
             if surprise > 0.9:
                 print(f"ğŸ›‘ REJECTING INPUT: Cognitive Overload (Surprise={surprise:.2f})")
                 self.hormones.update(Hormone.ADRENALINE, 50.0)
                 self.current_action_strategy = "REJECT" # Explicit rejection strategy
                 # Do NOT learn (protect weights from chaos)
                 # Do NOT reinforce memory
                 return

             # 3. SSM Decision: Update internal state strategy
             self.current_action_strategy = self.prediction_engine.get_action_strategy()
             print(f"ğŸ¤– Active Inference Strategy: {self.current_action_strategy} (Surprise={surprise:.2f})")
             
             # 4. Metabolic Impact (The "Taste" of Information)
             # Phase 15: Infantile Curiosity Logic
             if surprise < config.SURPRISE_THRESHOLD_CURIOSITY:
                 # SAFETY: Low error = Comfort/Truth
                 self.hormones.update(Hormone.SEROTONIN, 10.0) # Relax
                 self.hormones.update(Hormone.GLUCOSE, 2.0)
                 print(f"ğŸµ Safety. Surprise={surprise:.2f}")
                 
             elif surprise < config.SURPRISE_THRESHOLD_FEAR:
                 # CURIOSITY: Moderate error = Novelty!
                 # "What is this?" -> Release Dopamine
                 self.hormones.update(Hormone.DOPAMINE, 30.0)
                 self.hormones.update(Hormone.STIMULATION, 20.0)
                 # Curiosity consumes energy
                 self.hormones.update(Hormone.GLUCOSE, -1.0)
                 print(f"ğŸ‘¶ Curiosity! Surprise={surprise:.2f}, Dopamine spike.")
                 
             else:
                 # FEAR: High error = Chaos/Danger
                 self.hormones.update(Hormone.ADRENALINE, 40.0)
                 self.hormones.update(Hormone.STIMULATION, 50.0)
                 # Panic consumes massive energy
                 self.hormones.update(Hormone.GLUCOSE, -5.0)
                 print(f"ğŸ˜± Fear! Surprise={surprise:.2f}, Adrenaline spike.")
                 
             # 5. Learning (Model Update)
             # Only learn if not in panic
             self.cortex.learn(text, "User", surprise=surprise)
             
             # Phase 6: Deep Semantic Memory
             # High surprise = High importance (Flashbulb Memory)
             self.hippocampus.memorize(text, importance=surprise)
             
             if len(self.neurons) > 1000:
                 self.prune_neurons()

             # === Phase 30: Advanced Reasoning Loop (Common Sense) ===
             # Think about the input using the Knowledge Graph
             if hasattr(self, 'logic'):
                 thought = self.logic.ponder(text)
                 
                 # Activate the decided concept (Associative Priming)
                 if thought['decision']:
                     dec = thought['decision']
                     self.activate_concept(dec['name'], boost=0.5)
                     
                     # --- ğŸ§  THOUGHT STREAM (Visual Debugger) ---
                     import datetime
                     print("\n" + "="*60)
                     print(f"ğŸ§  THOUGHT STREAM | {datetime.datetime.now().strftime('%H:%M:%S')} | Strategy: {thought['strategy']}")
                     print("="*60)
                     print(f"Input: \"{text}\"")
                     print("-" * 60)
                     print(f"Anchor: {thought['anchor']}")
                     print("Candidates:")
                     for c in thought['candidates']:
                         mark = "â˜…" if c == thought['decision'] else " "
                         print(f"  {mark} {c['concept']} ({c['relation']}) ... Surprise: {c['sim_surprise']:.2f}")
                     print("-" * 60)
                     print(f"Decision: {dec['name']}")
                     print("="*60 + "\n")

        # Resonance for Input (Impact) - Outside Lock
        self.resonance.impact(text, force=1.0)
        
        # --- Environmental Resonance (Flashback) ---
        # å¼·ã„å…¥åŠ›(é•·ã„æ–‡ç« )ã‚„ã€ãƒ©ãƒ³ãƒ€ãƒ ãªç¢ºç‡ã§ã€Œç’°å¢ƒå…±é³´ã€ãŒç™ºç”Ÿã™ã‚‹
        # ãã®å ´ã®ç©ºæ°—(Geo Y)ã«ã‚ã‚‹éå»ã®è¨˜æ†¶ãŒä¸€æ–‰ã«å‘¼ã³èµ·ã“ã•ã‚Œã‚‹
        is_strong_input = len(text) > 10
        if is_strong_input or random.random() < 0.2:
            flashback_radius = 100
            fossils = self.cortex.excavate(random.randint(0, config.MSG_BRAIN_SIZE), self.current_geo_y, radius=flashback_radius)
            
            if fossils:
                count = min(3, len(fossils))
                restored = random.sample(fossils, count)
                print(f"âš¡ FLASHBACK TRIGGERED: Found {len(fossils)} echoes. Reviving {restored}...")
                
                with self.lock:
                    for old_word in restored:
                        # è»½ã„æƒ³èµ· (Nostalgia)
                        self.activate_concept(old_word, boost=0.3)
                        # ä¸€æ™‚çš„ã«å°‘ã—å¹¸ã›ã«ãªã‚‹ã‹ã€æ‚²ã—ããªã‚‹ã‹ã¯è¨˜æ†¶æ¬¡ç¬¬ã ãŒã€ã“ã“ã§ã¯ã€Œå…±é³´ã—ãŸã€äº‹å®Ÿã‚’Dopamineã¨ã™ã‚‹
                        self.hormones.update(Hormone.DOPAMINE, 5.0)

        # === Phase 18: Direct Conversation Response (Chat Mode) ===
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«å¯¾ã—ã¦ã€ç›´æ¥ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹
        # Blockingã‚’é˜²ããŸã‚åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
        threading.Thread(target=self._process_conversation, args=(text,), daemon=True).start()

    def _process_conversation(self, text: str):
        """
        Phase 18: Direct Response to User Input.
        Phase 19: Uses HDCBridge for memory injection.
        Runs in a background thread to avoid blocking.
        """
        try:
            # 1. Process through HDCBridge (Recall + G-Calc + Prompt Build)
            if hasattr(self, 'hdc_bridge') and self.hdc_bridge:
                bridge_result = self.hdc_bridge.process(text)
                reasoning_context = bridge_result.get("prompt", "")
            else:
                # Fallback to LogicEngine
                reasoning_context = ""
                if hasattr(self, 'logic_engine'):
                    thought_stream = self.logic_engine.ponder(text)
                    if thought_stream and thought_stream.get("decision"):
                        reasoning_context = self.logic_engine.get_context_prompt(thought_stream)
            
            # 2. Generate Response (AgniTranslator)
            if hasattr(self, 'translator') and self.translator:
                response_text = self.translator.generate_response(text, reasoning_context)
                
                if response_text:
                    # 3. Queue Speech
                    payload = {
                        "text": response_text,
                        "focus": "User Input",
                        "context": reasoning_context[:50] + "..." if reasoning_context else "Conversation",
                        "instability": 0.0
                    }
                    self.speech_queue.put(payload)
                    
                    # ä¼šè©±ãŒæˆç«‹ã—ãŸã®ã§æº€è¶³
                    self.hormones.update(Hormone.DOPAMINE, 10.0)
                    self.hormones.update(Hormone.SEROTONIN, 5.0)
                    
        except Exception as e:
            print(f"âš ï¸ Conversation Error: {e}")

    def _autonomous_speak(self):
        """
        Phase 19: Autonomous LLM Conversation.
        When bored or stimulated, generate self-directed speech using HDCBridge + Ollama.
        This allows Kaname to 'think aloud' intelligently and grow through internal dialogue.
        """
        try:
            # 1. Pick a random concept from memory as a conversation seed
            seed_word = self.memory.get_random_concept(refresh=True)
            if not seed_word or len(seed_word) < 2:
                return
            
            # 2. Construct an internal prompt (self-reflection)
            internal_prompts = [
                f"ã€Œ{seed_word}ã€ã«ã¤ã„ã¦æ€ã†ã“ã¨â€¦",
                f"æœ€è¿‘{seed_word}ã®ã“ã¨è€ƒãˆã¦ãŸâ€¦",
                f"{seed_word}ã£ã¦ä½•ã ã‚ã†ï¼Ÿ",
                f"ãµã¨{seed_word}ã‚’æ€ã„å‡ºã—ãŸâ€¦",
                f"{seed_word}â€¦ãªã‚“ã‹æ°—ã«ãªã‚‹"
            ]
            prompt = random.choice(internal_prompts)
            
            # 3. Process through HDCBridge for memory injection
            if hasattr(self, 'hdc_bridge') and self.hdc_bridge:
                bridge_result = self.hdc_bridge.process(prompt)
                context = bridge_result.get("prompt", "")
                action = bridge_result.get("action", "speak")
                
                # Only speak if G-calc favors it
                if action != "speak":
                    print(f"ğŸ¤« [Autonomous] G-calc chose '{action}' - staying quiet.")
                    return
            else:
                context = prompt
            
            # 4. Generate response using Ollama
            if hasattr(self, 'translator') and self.translator:
                response_text = self.translator.generate_response(prompt, context)
                
                if response_text and len(response_text) > 3:
                    # Clean output
                    response_text = response_text.strip()[:100]  # Limit length
                    
                    # 5. Queue for speech bubble
                    payload = {
                        "text": response_text,
                        "focus": seed_word,
                        "context": "Autonomous Thought",
                        "instability": 0.1
                    }
                    self.speech_queue.put(payload)
                    
                    # 6. Learn from self-reflection
                    self.hormones.update(Hormone.DOPAMINE, 3.0)  # Small satisfaction
                    self.hormones.update(Hormone.STIMULATION, 10.0)  # Reduce boredom
                    
                    print(f"ğŸ’¬ [Autonomous] Spoke about '{seed_word}': {response_text[:30]}...")
                    
        except Exception as e:
            print(f"âš ï¸ [Autonomous] Error: {e}")
    def save_memory(self, async_mode=True):
        """ 
        Run memory/cortex save.
        async_mode=True: Background thread (Non-blocking)
        async_mode=False: Foreground (Blocking, for Shutdown)
        """
        def _save_task():
            try:
                # Maintenance: Prune Dead Neurons (Working Memory cleanup)
                self.prune_neurons()
                
                # Flush Visual Buffer (Save the last thing seen)
                self.visual_bridge.flush()

                # Fossilize before saving (Keep Index Light)
                # Age Limit: 600s (10 mins) for demo. 
                # Memories older than 10m that are neutral will properly vanish from Index.
                self.memory.fossilize(age_limit=600)
                
                self.memory.save()
                # self.memory.export_visualization_data()  # Removed: 3D Map deleted by user request
                
                # Active Inference: Crystallize Observations (Abyssal Process)
                self.prediction_engine.crystallize()
                
                # Phase 26 -> Phase 6: RNN Re-training å‰Šé™¤ (No LLM)
                # ä»¥å‰ã¯ translator.train_from_memory() ã‚’å‘¼ã‚“ã§ã„ãŸãŒã€LLMä¸ä½¿ç”¨ã®ãŸã‚å‰Šé™¤
                pass
                
                # Pass async_mode to Cortex
                self.cortex.save(async_mode=async_mode) # Inherit mode from parent call
            except Exception as e:
                print(f"âš ï¸ Save Failed: {e}")

        if async_mode:
            t = threading.Thread(target=_save_task, daemon=True)
            t.start()
        else:
            print("ğŸ’¾ Saving Synchronously (Shutdown)...")
            _save_task()
            print("âœ… Save Complete.")

    def process_metabolism(self, cpu_percent, memory_percent, current_hour):
        """ ç”Ÿç†ä»£è¬ã®æ›´æ–° (Delegated to MetabolismManager) """
        if self.metabolism_manager:
            self.metabolism_manager.process(cpu_percent, memory_percent, current_hour)

    def process_autonomous_thought(self, heart_rate):
        """ Phase 18: è‡ªå¾‹æ€è€ƒ (Dream Waves) """
        # Use safe accessor to get random memory AND refresh timestamp (Extension of life)
        word = self.memory.get_random_concept(refresh=True)
        
        if not word:
            # ç´¢å¼•ãŒç©ºï¼ˆå…¨ã¦åŒ–çŸ³åŒ–ï¼‰ã¾ãŸã¯è¦‹ã¤ã‹ã‚‰ãªã„ -> å½·å¾¨ã† (Wander)
            drift_x = random.randint(-50, 50)
            drift_y = random.randint(-50, 50)
            
            # --- Metabolism-Linked Recall (Philosophy 2) ---
            # Glucose determines the "Range of Thought"
            glucose = self.hormones.get(Hormone.GLUCOSE)
            search_radius = 40 # Default (Narrow)
            if glucose > 70:
                search_radius = 150 # Broad/Creative
            elif glucose < 30:
                search_radius = 20 # Tunnel Vision (Survival)
                
            search_x = random.randint(0, config.MSG_BRAIN_SIZE)
            search_y = self.current_geo_y
            
            fossils = self.cortex.excavate(search_x, search_y, radius=search_radius)
            if fossils:
                word = random.choice(fossils)
                print(f"â›ï¸ Excavated Fossil: {word} (Radius: {search_radius})")
                
                # Re-Index (Resurrect) - Use lock for thread safety
                with self.memory.lock:
                    self.memory.concepts[word] = [search_x, int(search_y), time.time(), 1, 0.1]
            else:
                return None 
            
        # 1. Drift Impact (Sound)
        self.resonance.drift_impact(word)

        # 2. Mental Travel (Spirit moves to memory location)
        with self.lock:
             # Revive the thought as a neuron (Recall)
             self.activate_concept(word, boost=0.5)
             
             coords = self.memory.get_coords(word) 
             if coords and len(coords) >= 2:
                target_y = coords[1]
                # Slowly drift towards memory (Internalize)
                # Apply Soul Bias (State-Dependent Memory)
                soul_bias = self.prediction_engine.get_soul_bias() # -1.0 to 1.0
                
                # Soul pulls the target_y. 
                # If soul is 'High' (Pos), it prefers North (Low Y). If 'Low' (Neg), South (High Y).
                # Note: North=0 (Y-min), South=1024 (Y-max) in this system usually? 
                # Let's verify: In dashboard, Y is vertical. Usually 0 is top.
                # Assuming 0=North (High/Heaven), 1024=South (Deep/Abyss)
                
                # If bias is +1.0 (Positive State) -> Pull to 0 (North)
                # If bias is -1.0 (Negative State) -> Pull to 1024 (South)
                soul_target_bias = (soul_bias * -1.0) * 500 # Invert: +bias -> -Y (North)
                
                # The actual target is a mix of the memory location and the Soul's gravity
                final_target_y = target_y + soul_target_bias
                final_target_y = max(0, min(config.BRAIN_GEO_MAX, final_target_y))
                
                self.current_geo_y = self.current_geo_y * 0.9 + final_target_y * 0.1
                
                # Phase 22: Boredom accumulates if stuck
                if abs(self.current_geo_y - target_y) < 10:
                    self.hormones.update(Hormone.BOREDOM, 0.05)
                # (Removed duplicate geo_y calculation - Demon Audit Phase 22)

        # 3. Soliloquy (15% Chance to speak)
        impulse_ir = None
        
        # Prepare IR inside lock if needed (but cortex.speak is thread-safe on its own)
        # Brain chemicals need lock though
        with self.lock:
             if random.random() < 0.15:
                 # Phase 6: Deep Recall (What does this word mean to me?)
                 memories = self.hippocampus.recall(word, limit=3)
                 
                 ir_data = self.cortex.speak(word)
                 if ir_data:
                     # Inject Deep Memory
                     ir_data["deep_memory"] = [m["text"] for m in memories]
                     
                     ir_data["emotions"] = self.hormones.as_dict()
                     impulse_ir = ir_data

        if impulse_ir:
             # Phase 6: No-LLM - æ–­ç‰‡ã‚’ç›´æ¥è¿”ã™
             fragments = impulse_ir.get("fragments", [])
             text = "".join(fragments[:3]) if fragments else impulse_ir.get("concept", "")
             return {
                 "text": f"â€¦{text}â€¦",
                 "focus": word,
                 "context": self.memory.get_context(word)
             }
        
        return None

    def _forage_food(self):
        """
        Phase 5: é£Ÿæ–™æ¢ç´¢è¡Œå‹• (Foraging)
        å†·è”µåº« (food/) ã‚’æ¼ã‚Šã€ç„¡ã‘ã‚Œã°é’ç©ºæ–‡åº«ã¸è¡Œãã€‚
        """
        print("ğŸ½ï¸ Hunger pangs... Foraging for data...")
        
        # 1. å†·è”µåº«ãƒã‚§ãƒƒã‚¯ (Local Files)
        if self.feeder:
            files = self.feeder.check_food()
            if files:
                print(f"ğŸ§Š Found {len(files)} items in the fridge. Eating...")
                report = self.feeder.eat()
                if report:
                    from src.body.hormones import Hormone
                    # æ¶ˆåŒ–ã«ã‚ˆã‚‹è¡€ç³–å€¤å›å¾© (ä»®: +30.0)
                    self.hormones.update(Hormone.GLUCOSE, 30.0)
                    self.hormones.update(Hormone.DOPAMINE, 10.0)
                    self.input_stimulus(f"ã‚ãã€ç”Ÿãè¿”ã£ãŸ... (é£Ÿã¹ãŸã‚‚ã®: {len(files)} files)")
                return

        # 2. å¤šæ§˜ãªçŸ¥è­˜ã‚½ãƒ¼ã‚¹ (Wikipedia, News, RSS, etc.)
        # è»½ãæ‘˜ã‚€ (Snacking)
        if self.knowledge_manager and random.random() < 0.7:
             content = self.knowledge_manager.harvest_random()
             if content:
                 print(f"ğŸ“– Snacking on {content.source.name}...")
                 # é£Ÿã¹ã‚‹
                 if self.cortex and self.cortex.stomach:
                     self.cortex.stomach.eat(content.content)
                 
                 from src.body.hormones import Hormone
                 # è»½é£Ÿãªã®ã§å›å¾©ã¯æ§ãˆã‚
                 self.hormones.update(Hormone.GLUCOSE, 15.0)
                 self.hormones.update(Hormone.DOPAMINE, 5.0)
                 
                 self.input_stimulus(f"ãµã‚€ãµã‚€... ({content.source.name}: {content.title})")
                 return

        # 3. é’ç©ºæ–‡åº«ãƒã‚§ãƒƒã‚¯ (Aozora Bunko) - ãŒã£ã¤ã‚Šé£Ÿã¹ã‚‹ (Main Course)
        if self.aozora:
            print("ğŸ“– Going to Aozora Library...")
            text = self.aozora.harvest()
            if text:
                # é£Ÿã¹ã‚‹ (Synaptic Stomach)
                if self.cortex and self.cortex.stomach:
                    self.cortex.stomach.eat(text)
                
                from src.body.hormones import Hormone
                # è¡€ç³–å€¤å›å¾© (å¤§é‡)
                self.hormones.update(Hormone.GLUCOSE, 40.0)
                self.hormones.update(Hormone.DOPAMINE, 15.0) 
                
                # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º (ç°¡æ˜“)
                title = text.split('\n')[0] if text else "Unknown Book"
                if len(title) > 20: title = title[:20] + "..."
                
                self.input_stimulus(f"ç¾å‘³ã—ã‹ã£ãŸ...ã€‚ã€{title}ã€ã®å‘³ãŒã™ã‚‹ã€‚")
            else:
                 print("âš ï¸ Foraging failed. Nothing to eat...")
                 self.input_stimulus("ãŠè…¹ç©ºã„ãŸ...ä½•ã‚‚é£Ÿã¹ã‚‹ã‚‚ã®ãŒãªã„...")
    # ==========================================
    # â›ï¸ Phase 7: Minecraft Cognitive Loop
    # ==========================================
    # ==========================================
    # â›ï¸ Phase 9.2: Minecraft Spatial Memory
    # ==========================================
    def process_spatial_memory(self, pos_data):
        """ Delegate to SpatialCortex """
        if self.spatial:
            self.spatial.process_spatial_memory(pos_data)

    def decide_minecraft_intent(self, state):
        """ Delegate to SpatialCortex """
        if self.spatial:
            return self.spatial.decide_intent(state)
        return None

    # ==========================================
    # ğŸ‘ï¸ Phase 10: Vision & Visual Cortex
    # ==========================================
    def process_visual_memory(self, cursor_data):
        """
        Phase 14: è¦–è¦šæƒ…å ±ã®å‡¦ç† (Visual Memory)
        Raycasting (è¦–ç·š) ã§è¦‹ãŸã‚‚ã®ã‚’çŸ­æœŸè¨˜æ†¶ã—ã€æ„Ÿæƒ…ã‚’èª˜ç™ºã™ã‚‹ã€‚
        """
        try:
            if not cursor_data: return
            
            block_name = cursor_data.get("name") # e.g. "minecraft:grass_block" or "oak_log"
            if not block_name: return
            
            # ã‚³ãƒ³ã‚»ãƒ—ãƒˆåŒ– (Concept Mapping)
            simple_name = block_name.replace('minecraft:', '').replace('_', ' ')
            
            # Phase 14: Minecraft Block/Entity Translation
            MC_TO_JP = {
                # Blocks
                "stone": "çŸ³", "cobblestone": "ä¸¸çŸ³", "dirt": "åœŸ", "grass block": "è‰ãƒ–ãƒ­ãƒƒã‚¯",
                "oak log": "ã‚ªãƒ¼ã‚¯ã®åŸæœ¨", "birch log": "ç™½æ¨ºã®åŸæœ¨", "spruce log": "ãƒˆã‚¦ãƒ’ã®åŸæœ¨",
                "oak planks": "ã‚ªãƒ¼ã‚¯ã®æ¿æ", "diamond ore": "ãƒ€ã‚¤ãƒ¤é‰±çŸ³", "gold ore": "é‡‘é‰±çŸ³",
                "iron ore": "é‰„é‰±çŸ³", "coal ore": "çŸ³ç‚­é‰±çŸ³", "lapis ore": "ãƒ©ãƒ”ã‚¹é‰±çŸ³",
                "redstone ore": "ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¼ãƒ³é‰±çŸ³", "emerald ore": "ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰é‰±çŸ³",
                "water": "æ°´", "lava": "æº¶å²©", "sand": "ç ‚", "gravel": "ç ‚åˆ©",
                "obsidian": "é»’æ›œçŸ³", "bedrock": "å²©ç›¤", "crafting table": "ä½œæ¥­å°",
                "furnace": "ã‹ã¾ã©", "chest": "ãƒã‚§ã‚¹ãƒˆ", "torch": "ãŸã„ã¾ã¤",
                # Entities (from nearestMob)
                "zombie": "ã‚¾ãƒ³ãƒ“", "skeleton": "ã‚¹ã‚±ãƒ«ãƒˆãƒ³", "spider": "ã‚¯ãƒ¢",
                "creeper": "ã‚¯ãƒªãƒ¼ãƒ‘ãƒ¼", "enderman": "ã‚¨ãƒ³ãƒ€ãƒ¼ãƒãƒ³", "witch": "ã‚¦ã‚£ãƒƒãƒ",
                "pig": "ãƒ–ã‚¿", "cow": "ã‚¦ã‚·", "sheep": "ãƒ’ãƒ„ã‚¸", "chicken": "ãƒ‹ãƒ¯ãƒˆãƒª",
                "wolf": "ã‚ªã‚ªã‚«ãƒŸ", "cat": "ãƒã‚³", "horse": "ã‚¦ãƒ", "villager": "æ‘äºº",
            }
            
            # Phase 14: Innate Emotion Responses
            MC_EMOTIONS = {
                # Danger (Cortisol/Adrenaline)
                "lava": {"cortisol": 15, "adrenaline": 10, "log": "ğŸ”¥ DANGER: æº¶å²©!"},
                "zombie": {"cortisol": 20, "adrenaline": 25, "log": "ğŸ‘¹ THREAT: ã‚¾ãƒ³ãƒ“!"},
                "skeleton": {"cortisol": 25, "adrenaline": 20, "log": "ğŸ’€ THREAT: ã‚¹ã‚±ãƒ«ãƒˆãƒ³!"},
                "creeper": {"cortisol": 40, "adrenaline": 30, "log": "ğŸ’¥ EXTREME DANGER: ã‚¯ãƒªãƒ¼ãƒ‘ãƒ¼!"},
                "spider": {"cortisol": 15, "adrenaline": 15, "log": "ğŸ•·ï¸ THREAT: ã‚¯ãƒ¢!"},
                "enderman": {"cortisol": 30, "adrenaline": 20, "log": "ğŸ‘ï¸ THREAT: ã‚¨ãƒ³ãƒ€ãƒ¼ãƒãƒ³!"},
                # Joy (Dopamine)
                "diamond ore": {"dopamine": 30, "log": "ğŸ’ TREASURE: ãƒ€ã‚¤ãƒ¤ç™ºè¦‹!"},
                "gold ore": {"dopamine": 20, "log": "ğŸ¥‡ TREASURE: é‡‘ç™ºè¦‹!"},
                "emerald ore": {"dopamine": 25, "log": "ğŸ’š TREASURE: ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ç™ºè¦‹!"},
                # Comfort (Oxytocin)
                "pig": {"oxytocin": 10, "log": "ğŸ· FRIENDLY: ãƒ–ã‚¿ç™ºè¦‹!"},
                "cow": {"oxytocin": 10, "log": "ğŸ„ FRIENDLY: ã‚¦ã‚·ç™ºè¦‹!"},
                "sheep": {"oxytocin": 10, "log": "ğŸ‘ FRIENDLY: ãƒ’ãƒ„ã‚¸ç™ºè¦‹!"},
                "cat": {"oxytocin": 15, "log": "ğŸ± FRIENDLY: ãƒã‚³ç™ºè¦‹!"},
                "wolf": {"oxytocin": 8, "log": "ğŸº FRIENDLY: ã‚ªã‚ªã‚«ãƒŸç™ºè¦‹!"},
                # Safety (Serotonin)
                "torch": {"serotonin": 5, "log": None},
                "crafting table": {"serotonin": 3, "log": None},
                "water": {"serotonin": 2, "log": None},
            }
            
            jp_name = MC_TO_JP.get(simple_name, simple_name)
            
            # 2. æ„Ÿæƒ…åå¿œ (Innate Response)
            emotion_key = simple_name.lower()
            if emotion_key in MC_EMOTIONS:
                response = MC_EMOTIONS[emotion_key]
                if response.get("cortisol"):
                    self.hormones.update(Hormone.CORTISOL, response["cortisol"])
                if response.get("adrenaline"):
                    self.hormones.update(Hormone.ADRENALINE, response["adrenaline"])
                if response.get("dopamine"):
                    self.hormones.update(Hormone.DOPAMINE, response["dopamine"])
                if response.get("oxytocin"):
                    self.hormones.update(Hormone.OXYTOCIN, response["oxytocin"])
                if response.get("serotonin"):
                    self.hormones.update(Hormone.SEROTONIN, response["serotonin"])
                if response.get("log"):
                    print(f"ğŸ‘ï¸ [Vision] {response['log']}")
            
            # 3. è¨˜æ†¶ã¸ã®åˆ»å° (Spatial Memory)
            position = cursor_data.get("position")
            if position and jp_name:
                # åº§æ¨™ä»˜ãã§è¨˜æ†¶
                self.memory.reinforce(jp_name, 0.1)  # Weak positive valence
                # æ¦‚å¿µãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ´»æ€§åŒ–
                self.activate_concept(jp_name, boost=0.5)
            
            # DEBUG: ç¨€ã«è¦–è¦šãƒ­ã‚°
            if random.random() < 0.02:
                 print(f"ğŸ‘ï¸ Saw: {jp_name} ({cursor_data.get('displayName', '')})")

        except Exception as e:
            print(f"âš ï¸ [BRAIN] Visual Process Error: {e}")


    # Phase 15.1: Motor gradient methods moved to motor_cortex.py

    # Phase 21: Cognitive Game Loop Support
    def think_soliloquy(self, sensory_text: str) -> str:
        """
        [Cognitive Loop]
        è¦–è¦šæƒ…å ±(ãƒ†ã‚­ã‚¹ãƒˆ)ã‚’å—ã‘å–ã‚Šã€ç‹¬ã‚Šè¨€(æ€è€ƒ)ã‚’ç”Ÿæˆã—ã¦è¿”ã™ã€‚
        MVPã§ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§å¿œç­”ã™ã‚‹ãŒã€å°†æ¥çš„ã«ã¯LLM/Tazunaã¨é€£æºã™ã‚‹ã€‚
        """
        # 1. è¦–è¦šæƒ…å ±ã‚’ãƒ­ã‚°
        print(f"\nğŸ‘ï¸ [VISION] {sensory_text}")
        
        # Phase 12: Advanced Reasoning Loop
        reasoning_context = ""
        if hasattr(self, 'logic_engine'):
             thought_stream = self.logic_engine.ponder(sensory_text)
             if thought_stream.get("decision"):
                 decision = thought_stream["decision"]
                 print(f"ğŸ§  THOUGHT STREAM: '{sensory_text}' -> {decision['name']} (Score: {decision.get('score', 0):.2f})")
                 print(f"   Reason: {thought_stream.get('strategy', 'Unknown')}")
                 reasoning_context = self.logic_engine.get_context_prompt(thought_stream)
        
        # 2. Tazunaã®çŠ¶æ…‹ã‚’å–å¾—
        tazuna_mode = "NORMAL"
        tazuna_temp = 1.0
        if self.tazuna and hasattr(self.tazuna, 'current_signal'):
             # Note: current_signal might not be stored, but we can assume defaults
             pass

        # 3. æ€è€ƒç”Ÿæˆ (Phase 16: Logic -> Ollama)
        if hasattr(self, 'translator') and self.translator and reasoning_context:
            thought = self.translator.generate_response(sensory_text, reasoning_context)
            if thought:
                print(f"ğŸ—£ï¸ [KANAME] {thought}")
                return thought

        # Fallback: Dummy Logic for MVP
        thought = ""
        
        if "å£" in sensory_text:
             thought += "å£ãŒã‚ã‚‹ãªã€‚ã¶ã¤ã‹ã‚‰ãªã„ã‚ˆã†ã«é¿ã‘ã‚ˆã†ã€‚"
        if "é¤Œ" in sensory_text:
             thought += "ãŠã€é¤Œã‚’è¦‹ã¤ã‘ãŸã€‚"
             
        # æ–¹å‘ã®æ±ºå®š (GameParserãŒç†è§£ã§ãã‚‹è¨€è‘‰ã‚’å…¥ã‚Œã‚‹)
        intent = ""
        if "åŒ—ã«å£" in sensory_text and "è¥¿ã«å£" not in sensory_text:
             intent = "å·¦(è¥¿)ã«é€ƒã’ã‚ˆã†ã€‚"
        elif "åŒ—ã«å£" in sensory_text:
             intent = "å³(æ±)ã«è¡Œã“ã†ã€‚"
        elif "é¤Œã¯ä¸Š" in sensory_text or "åŒ—æ–¹å‘" in sensory_text:
             intent = "ä¸Š(åŒ—)ã«é€²ã‚‚ã†ã€‚"
        elif "é¤Œã¯ä¸‹" in sensory_text or "å—æ–¹å‘" in sensory_text:
             intent = "ä¸‹(å—)ã«é€²ã‚‚ã†ã€‚"
        elif "é¤Œã¯å·¦" in sensory_text or "è¥¿æ–¹å‘" in sensory_text:
             intent = "å·¦(è¥¿)ã«é€²ã‚‚ã†ã€‚"
        elif "é¤Œã¯å³" in sensory_text or "æ±æ–¹å‘" in sensory_text:
             intent = "å³(æ±)ã«é€²ã‚‚ã†ã€‚"
        else:
             intent = "ã¨ã‚Šã‚ãˆãšå‰ã«é€²ã‚‚ã†ã€‚" # Default

        full_thought = f"{thought} {intent} {reasoning_context}"

        # 4. æ€è€ƒã‚’å‡ºåŠ›
        print(f"ğŸ§  [THOUGHT] \"{full_thought}\"")
        return full_thought
